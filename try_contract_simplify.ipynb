{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb84acf",
   "metadata": {
    "ExecuteTime": { 
     "end_time": "2025-10-08T17:42:07.768613Z",
     "start_time": "2025-10-08T17:42:06.029693Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = r\"C:\\Users\\hp\\PycharmProjects\\Mini_Project\\CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf\"\n",
    "\n",
    "text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "pdf_content = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96d32c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:43:05.340256Z",
     "start_time": "2025-10-08T17:42:39.555449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed page 1/12\n",
      "Processed page 2/12\n",
      "Processed page 3/12\n",
      "Processed page 4/12\n",
      "Processed page 5/12\n",
      "Processed page 6/12\n",
      "Processed page 7/12\n",
      "Processed page 8/12\n",
      "Processed page 9/12\n",
      "Processed page 10/12\n",
      "Processed page 11/12\n",
      "Processed page 12/12\n",
      "Exhibit 10.33\n",
      "\n",
      "Last Updated: April 6, 2007\n",
      "\n",
      "CHASE AFFILIATE AGREEMENT\n",
      "\n",
      "THIS AGREEMENT sets forth the terms and conditions agreed to between Chase Bank USA, N.A. (?Chase?) and you as an “Affiliate” in the Chase\n",
      "Affiliate Program (the “Affiliate Program”). Once accepted into the Affiliate Program, an Affiliate can establish links from the Affiliate’s Website to\n",
      "[Chase.com]. Chase will pay Affiliate a fee for each approved credit card account that originates from a link in Affiliate’s Website.\n",
      "\n",
      "THIS IS A LEGAL AND CONTRACTUALLY BINDING AGREEMENT BETWEEN AFFILIATE AND CHASE. TO APPLY TO THE AFFILIATE\n",
      "PROGRAM, YOU MUST COMPLETE AND SUBMIT THE AFFILIATE REGISTRATION FORM AND CLICK ON THE “AGREE” BUTTON BELOW\n",
      "TO INDICATE YOUR WILLINGNESS TO BE BOUND TO CHASE BY THIS AGREEMENT. THIS AGREEMENT WILL TAKE EFFECT IF AND\n",
      "WHEN CHASE REVIEWS AND ACCEPTS YOUR REGISTRATION FORM AND PROVIDES YOU NOTICE OF ACCEPTANCE. BY SUBMITTING\n",
      "YOUR REGISTRATION FORM, AFFILIATE CERTIFIES THAT YOU HAVE READ AND UNDERS\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = r\"C:\\Users\\hp\\PycharmProjects\\Mini_Project\\CreditcardscomInc_20070810_S-1_EX-10.33_362297_EX-10.33_Affiliate Agreement.pdf\"\n",
    "\n",
    "# Tell pytesseract where Tesseract OCR is installed\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Convert PDF pages to images using Poppler\n",
    "pages = convert_from_path(pdf_path, poppler_path=r\"C:\\Users\\hp\\Downloads\\Release-25.07.0-0\\poppler-25.07.0\\Library\\bin\")\n",
    "\n",
    "ocr_text = \"\"\n",
    "for i, page in enumerate(pages):\n",
    "    # Extract text from each page using OCR\n",
    "    text = pytesseract.image_to_string(page)\n",
    "    ocr_text += text + \"\\n\"\n",
    "    print(f\"Processed page {i+1}/{len(pages)}\")\n",
    "\n",
    "# Print first 1000 characters of extracted text\n",
    "print(ocr_text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c70dc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:14:04.002857Z",
     "start_time": "2025-10-08T17:14:03.441130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 97.80%\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# Take first 100000 characters to compare\n",
    "pdf_snippet = pdf_content[:100000]\n",
    "ocr_snippet = ocr_text[:100000]\n",
    "\n",
    "# Calculate similarity ratio\n",
    "similarity = difflib.SequenceMatcher(None, pdf_snippet, ocr_snippet).ratio()\n",
    "\n",
    "print(f\"Similarity: {similarity*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aa3f518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:28:50.797489Z",
     "start_time": "2025-10-08T17:28:50.790322Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd373790f196139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:33:03.020407Z",
     "start_time": "2025-10-08T17:33:02.992286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\PycharmProjects\\Mini_Project\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "#\"C:\\Users\\hp\\PycharmProjects\\Mini_Project\\.venv\\Scripts\\python.exe\" -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf68d6e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:44:43.758384Z",
     "start_time": "2025-10-08T17:44:40.380457Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee2d9bde1a217d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:13:33.892207Z",
     "start_time": "2025-10-08T18:13:30.066145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (4.57.0)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\pycharmprojects\\mini\\.venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install faiss-cpu\n",
    "!{sys.executable} -m pip install --upgrade sentencepiece transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e1da05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T17:59:53.456952Z",
     "start_time": "2025-10-08T17:58:39.657701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\PycharmProjects\\mini\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index is ready with 21 documents\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Split OCR text into chunks (paragraphs or 500-word blocks)\n",
    "def split_text(text, max_words=200):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "texts = split_text(ocr_text)\n",
    "\n",
    "# Encode into embeddings\n",
    "embeddings = model.encode(texts)        # shape: (num_chunks, dim)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Build FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)    # inner product = cosine similarity (since normalized)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index is ready with\", index.ntotal, \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca96405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:02:41.162588Z",
     "start_time": "2025-10-08T18:02:41.002754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is restricted content in this agreement?\n",
      "\n",
      "Match 1 (score=0.4159):\n",
      "Chase, its shareholders, officers, directors, employees, agents, affiliates and their respective directors, officers, employees and agents, successors and assigns, from and against any and all claims, demands, losses, liabilities, damages or expenses (including attorneys’ fees and costs) of any nature whatsoever incurred or suffered by Chase (collectively the “losses”), in so far as such losses (or actions in respect thereof) arise out of, are related to, or are based on (i) the breach of any representation, warranty, or covenant made by Affiliate herein; or (ii) any claim related to Affiliate’s site. 18. Confidentiality Except as otherwise provided in this Agreement or with the consent of the other party hereto, each of the parties hereto agrees that all information including, without limitation, the terms of this Agreement, business and financial information, customer and vendor lists, and pricing and sales information, concerning Chase, Customer or Affiliate shall remain strictly confidential and secret and shall not be utilized, directly or indirectly, by such party for its own business purposes or for any other purpose except and solely to the extent necessary to exercise rights and perform obligations under this Agreement. The foregoing restrictions will not apply to information to the extent it (i)\n",
      "\n",
      "Match 2 (score=0.4003):\n",
      "Agreement in the event that any Restricted Content is incorporated on Affiliate’s site after acceptance of your registration form and the commencement of the term of this Agreement. Chase may also terminate this Agreement if your site is deemed unsuitable based on the criteria below: * Manipulates key word searches on portals * Misrepresents itself as a Chase Website by altering the visual “look and feel” of or text from Chase’s site, and/or engage in “framing” the Chase Website * Engages in domain squatting * Engages in spamming or unsolicited commercial e-mail * Engages in unauthorized telemarketing or remarketing of Chase Credit Card offers via telephone * Uses Chase products and services in the domain name, URL or URI, including, but not limited to, any combination of the following words: °JP * MORGAN * CHASE * MANHATTAN * AARP * AMAZON.COM * BALL STATE UNIVERSITY * BORDERS * BRITISH AIRWAYS * CASH PLUS * CHASE FREEDOM * CENTRAL MICHIGAN UNIVERSITY * CONTINENTAL * CORNELL UNIVERSITY * DISNEY * DUKE UNIVERSITY * FLEXIBLE REWARDS * FREE CASH * HARVARD COOP * HESS * HOME IMPROVEMENT * LEHIGH UNIVERSITY * LOUISIANA STATE UNIVERSITY * MARATHON * MARRIOTT * MIAMI UNIVERSITY * OHIO\n",
      "\n",
      "Match 3 (score=0.3822):\n",
      "cards for their own use are NOT in violation of this Agreement. 14, Trademarks All Chase trademarks, trade names and service marks (collectively, the “Marks”) are the exclusive property of Chase. Notwithstanding anything set forth in this Agreement, Chase reserves full ownership of the Marks and the Licensed Materials (as defined below). All use of the Marks by Affiliate is limited solely to the use contemplated by this Agreement. All use of Chase Marks by Affiliate is subject to the prior written approval of Chase. 15. Licenses and Use of the Chase Logos and Trademarks Chase grants Affiliate a non-exclusive, nontransferable, revocable right to (a) access the Chase site through the links solely in accordance with the terms of this Agreement and (b) solely in connection with such links, to use Chase’s logos, trade names, trademarks, and similar identifying material relating to Chase (collectively, the “Licensed Materials”), for the sole purpose of booking Chase products. Prior to using any of the Licensed Materials, Affiliate will submit to Chase for approval a draft of all proposed material that incorporates the Licensed Materials, together with a brief statement setting forth the proposed use of such materials and any other background or supporting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Example: Semantic search in a legal contract\n",
    "# -----------------------------\n",
    "\n",
    "# Assume you already have:\n",
    "# texts -> list of clauses/sentences\n",
    "# model -> SentenceTransformer model\n",
    "# index -> FAISS index built from embeddings of texts\n",
    "\n",
    "# Example query\n",
    "query = \"What is restricted content in this agreement?\"\n",
    "\n",
    "# Step 1: Encode query and normalize for cosine similarity\n",
    "query_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "query_emb = query_emb.astype(\"float32\")\n",
    "\n",
    "# Step 2: Search top-k matches in FAISS index\n",
    "top_k = 3\n",
    "D, I = index.search(query_emb, k=top_k)  # D: scores, I: indices of matches\n",
    "\n",
    "# Step 3: Display results\n",
    "print(\"\\nQuery:\", query)\n",
    "for rank, idx in enumerate(I[0]):\n",
    "    print(f\"\\nMatch {rank+1} (score={D[0][rank]:.4f}):\")\n",
    "    print(texts[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1fa199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:13:56.698280Z",
     "start_time": "2025-10-08T18:13:56.600361Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load T5 model (offline once downloaded, or cache)\u001b[39;00m\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mt5-small\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m tokenizer = \u001b[43mT5Tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(model_name)\n\u001b[32m      6\u001b[39m model = T5ForConditionalGeneration.from_pretrained(model_name)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimplify_text\u001b[39m(text):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\mini\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2157\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   2155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m2157\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\mini\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2143\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   2140\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   2142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m2143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load T5 model (offline once downloaded, or cache)\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def simplify_text(text):\n",
    "    \"\"\"\n",
    "    Simplify legal/complex text using T5 model\n",
    "    \"\"\"\n",
    "    # T5 can be instructed with a \"simplify:\" prefix\n",
    "    input_text = \"simplify: \" + text\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    simplified = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Exhibit 10.33\n",
      "\n",
      "Last Updated: April 6, 2007\n",
      "\n",
      "CHASE AFFILIATE AGREEMENT\n",
      "\n",
      "THIS AGREEMENT sets forth the terms and conditions agreed to between Chase Bank USA, N.A. (?Chase?) and you as an “Affiliate” in the Chase\n",
      "Affiliate Program (the “Affiliate Program”). Once accepted into the Affiliate Program, an Affiliate can establish links from the Affiliate’s Website to\n",
      "[Chase.com]. Chase will pay Affiliate a fee for each approved credit card account that originates from a link in Affiliate’s Website.\n",
      "\n",
      "THIS IS A LEGAL AND CONTRACTUALLY BINDING AGREEMENT BETWEEN AFFILIATE AND CHASE. TO APPLY TO THE AFFILIATE\n",
      "PROGRAM, YOU MUST COMPLETE AND SUBMIT THE AFFILIATE REGISTRATION FORM AND CLICK ON THE “AGREE” BUTTON BELOW\n",
      "TO INDICATE YOUR WILLINGNESS TO BE BOUND TO CHASE BY THIS AGREEMENT. THIS AGREEMENT WILL TAKE EFFECT IF AND\n",
      "WHEN CHASE REVIEWS AND ACCEPTS YOUR REGISTRATION FORM AND PROVIDES YOU NOTICE OF ACCEPTANCE. BY SUBMITTING\n",
      "YOUR REGISTRATION FORM, AFFILIATE CERTIFIES THAT YOU HAVE READ AND UNDERSTAND THE TERMS SET FORTH BELOW, AND\n",
      "THAT YOU ARE AUTHORIZED TO SUBMIT THIS REGISTRATION FORM BY THE NAMED AFFILIATE.\n",
      "\n",
      "In connection with your participation in the Affiliate Program, Affiliate and Chase agree as follows:\n",
      "\n",
      "1. Enrollment in the Affiliate Program; Restricted Content\n",
      "\n",
      "To enroll in the Affiliate Program, you must submit a complete “Affiliate Registration Form” via the Chase Affiliate Website:\n",
      "\n",
      "For new affiliates: https://ssl.linksynergy.com/php-bin/reg/sregister.shtml?mid=229 1\n",
      "\n",
      "For existing affiliates: http://www.linkshare.com/joinprograms?0id=87909\n",
      "\n",
      "Chase will evaluate your registration form and will notify you via e-mail of the acceptance or rejection of your registration form. Chase reserves, in\n",
      "its sole discretion, with or without reason, the right to accept or reject your registration into the Chase Affiliate Program, including but not limited to\n",
      "\n",
      "a determination that your site is unsuitable for or incompatible with the Affiliate Program based on the following criteria (collectively “Restricted\n",
      "Content”):\n",
      "\n",
      "* Incorporates images or content that is any way unlawful, offensive, profane, harmful, threatening, defamatory, obscene, harassing or racially,\n",
      "ethically or otherwise objectionable\n",
      "\n",
      "* Promote illegal activities, including gambling\n",
      "* Promotes or depicts sexually explicit, obscene or pornographic images\n",
      "* Promotes or depicts violence or hate speech\n",
      "\n",
      "* Promotes discrimination based on race, sex, religion, nationality, disability, sexual orientation or age\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "* Incorporates any materials which infringe or assist others to infringe on any copyright, trademark or other intellectual property rights\n",
      "\n",
      "* Contains or promotes politically sensitive or controversial issues\n",
      "\n",
      "Chase also reserves the right to terminate this Agreement in the event that any Restricted Content is incorporated on Affiliate’s site after\n",
      "acceptance of your registration form and the commencement of the term of this Agreement. Chase may also terminate this Agreement if your site is\n",
      "deemed unsuitable based on the criteria below:\n",
      "\n",
      "* Manipulates key word searches on portals\n",
      "\n",
      "* Misrepresents itself as a Chase Website by altering the visual “look and feel” of or text from Chase’s site, and/or engage in “framing” the Chase\n",
      "Website\n",
      "\n",
      "* Engages in domain squatting\n",
      "\n",
      "* Engages in spamming or unsolicited commercial e-mail\n",
      "\n",
      "* Engages in unauthorized telemarketing or remarketing of Chase Credit Card offers via telephone\n",
      "\n",
      "* Uses Chase products and services in the domain name, URL or URI, including, but not limited to, any combination of the following words:\n",
      "\n",
      "°JP\n",
      "\n",
      "* MORGAN\n",
      "\n",
      "* CHASE\n",
      "\n",
      "* MANHATTAN\n",
      "\n",
      "* AARP\n",
      "\n",
      "* AMAZON.COM\n",
      "\n",
      "* BALL STATE UNIVERSITY\n",
      "\n",
      "* BORDERS\n",
      "\n",
      "* BRITISH AIRWAYS\n",
      "\n",
      "* CASH PLUS\n",
      "\n",
      "* CHASE FREEDOM\n",
      "\n",
      "* CENTRAL MICHIGAN UNIVERSITY\n",
      "* CONTINENTAL\n",
      "\n",
      "* CORNELL UNIVERSITY\n",
      "\n",
      "* DISNEY\n",
      "\n",
      "* DUKE UNIVERSITY\n",
      "\n",
      "* FLEXIBLE REWARDS\n",
      "\n",
      "* FREE CASH\n",
      "\n",
      "* HARVARD COOP\n",
      "\n",
      "* HESS\n",
      "\n",
      "* HOME IMPROVEMENT\n",
      "\n",
      "* LEHIGH UNIVERSITY\n",
      "\n",
      "* LOUISIANA STATE UNIVERSITY\n",
      "* MARATHON\n",
      "\n",
      "* MARRIOTT\n",
      "\n",
      "* MIAMI UNIVERSITY\n",
      "\n",
      "* OHIO UNIVERSITY\n",
      "\n",
      "* OVERSTOCK\n",
      "\n",
      "* PERFECT CARD\n",
      "\n",
      "* PRIORITY CLUB / HOLIDAY INN\n",
      "* SONY\n",
      "\n",
      "* SOUTHERN ILLINOIS UNIVERSITY\n",
      "* SPEEDWAY SUPER AMERICA.\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "* STARBUCKS\n",
      "\n",
      "* SUBARU\n",
      "\n",
      "* TEMPLE UNIVERSITY\n",
      "\n",
      "* TOYS \"R\" US\n",
      "\n",
      "* TRAVEL PLUS\n",
      "\n",
      "* TRUMP\n",
      "\n",
      "* ULTIMATE REWARDS\n",
      "\n",
      "* UNITED\n",
      "\n",
      "* UNIVERSAL\n",
      "\n",
      "* UNIVERSITY OF ARIZONA ATHLETICS\n",
      "* UNIVERSITY OF CHICAGO\n",
      "\n",
      "* UNIVERSITY OF FLORIDA,\n",
      "\n",
      "* UNIVERSITY OF HOUSTON\n",
      "\n",
      "* UNIVERSITY OF IDAHO\n",
      "\n",
      "* UNIVERSITY OF KENTUCKY\n",
      "\n",
      "* UNIVERSITY OF MARYLAND\n",
      "\n",
      "* UNIVERSITY OF MEMPHIS\n",
      "\n",
      "* UNIVERSITY OF MINNESOTA ATHLETICS\n",
      "* UNIVERSITY OF NOTRE DAME\n",
      "\n",
      "* UNIVERSITY OF OKLAHOMA\n",
      "\n",
      "* UNIVERSITY OF OREGON\n",
      "\n",
      "* UNIVERSITY OF SOUTH CAROLINA\n",
      "\n",
      "* UNIVERSITY OF TENNESSEE\n",
      "\n",
      "* UNIVERSITY OF VIRGINIA\n",
      "\n",
      "* UTAH STATE UNIVERSITY\n",
      "\n",
      "* VALUE MILES\n",
      "\n",
      "* VIRGINIA TECH APPROVED ACCOUNT\n",
      "* VOLKSWAGEN\n",
      "\n",
      "* WESTERN ILLINOIS UNIVERSITY\n",
      "\n",
      "* YALE UNIVERSTIY\n",
      "\n",
      "* Uses a proxy server or redirector server to proxy Chase web pages or web sites through your website, URL or URI\n",
      "\n",
      "* Otherwise violates intellectual property rights, including, without limitation, “scraping” text or images from Chase’s Website\n",
      "* Does not clearly state an online privacy policy to its visitors\n",
      "\n",
      "* Is based outside of the United States\n",
      "\n",
      "* Is otherwise considered offensive or inappropriate, at Chase’s discretion\n",
      "2. Affiliate Responsibilities:\n",
      "\n",
      "* Affiliate cannot use or implement creative that is not available through the LinkShare affiliate interface.\n",
      "\n",
      "* Affiliates may not harvest or collect personal information, or email addresses using the Chase brand without the written consent of Chase\n",
      "\n",
      "° If Affiliate manages a sub-affiliate network, upon Chase’s request, Affiliate shall promptly provide Chase with a current, written list identifying the\n",
      "sub-affiliates or other third parties associated.\n",
      "\n",
      "* Chase reserves the right to review and approve all sub-affiliate partners.\n",
      "\n",
      "* Chase shall only use the list for the sole purpose of administering the program and monitoring proper usage, and will not poach or contact\n",
      "subaffiliates directly.\n",
      "\n",
      "* Affiliates will not use the following product keyword search terms. (See Appendix)\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "* If Affiliate manages a sub-affiliate network, the Affiliate may not pay sub-affiliates or other partners higher referral fees than the lowest tier of the\n",
      "public offer ($55.00).\n",
      "\n",
      "* Affiliate is prohibited from (a) installing spyware on another person’s computer, (b) causing spyware to be installed on another person’s\n",
      "computer, or (c) using a context based triggering mechanism to display an advertisement that partially or wholly covers or obscures paid\n",
      "advertising or other content on an Internet website in a way that interferes with a user’s ability to view the Internet website.\n",
      "\n",
      "3. Referral Fee\n",
      "\n",
      "For each Approved Account (as defined in section 4 below) received through Affiliate’s site, Affiliate will earn a referral fee calculated in\n",
      "accordance with the schedule set forth below (“Commission”) paid monthly.\n",
      "\n",
      "* Tiered or flat commission based on private offer terms in the network.\n",
      "\n",
      "Chase reserves the right to alter above referral fees from time to time upon written notice to Affiliate of such change.\n",
      "\n",
      "4. Approved Account\n",
      "\n",
      "For purposes of determining Affiliate’s Commission, an “Approved Account” means any Chase credit card application that is: (i) submitted by any\n",
      "user who clicks on an e-mail, banner or any other advertising material from A ffiliate’s Website; (ii) is approved by Chase; and (iii) is reported as\n",
      "approved by Chase to Affiliate.\n",
      "\n",
      "5.Term of this Agreement\n",
      "\n",
      "The term of this Agreement will commence on the date that the Affiliate Registration Form is approved by Chase and will end when terminated by\n",
      "either party. Either Affiliate or Chase may terminate this Agreement at any time, with or without cause, by giving the other party written or e-mail\n",
      "notice of termination. At the time of termination, any links to Chase’s Website must be removed immediately. Affiliate will continue to receive\n",
      "Commission payments for all Approved Accounts placed during the term of this Agreement. Notwithstanding the foregoing, Chase may\n",
      "\n",
      "terminate this Agreement if Affiliate does not comply with the terms and conditions herein.\n",
      "\n",
      "6. Links\n",
      "\n",
      "Affiliate agrees to place Chase’s links provided by Linkshare NetworkTM which manages the Affiliate Program (“Links”) on its Affiliate’s website.\n",
      "Affiliate is responsible for obtaining prior written approval from the Chase Affiliate manager or Linkshare Network to link any or all other sites\n",
      "owned or managed by the Affiliate, other than the site that was approved at the time of original registration. Affiliate may select or remove Links, at\n",
      "\n",
      "any time without prior approval from Chase. Affiliate is also responsible for removing and/or informing Chase of potential inactive or misdirected\n",
      "Links. Affiliate agrees to cooperate with Chase in establishing and maintaining Links.\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "7. Order Processing\n",
      "\n",
      "Chase will be solely responsible for processing each order placed by a customer from Affiliate’s Links. Customers may only use the Chase on-line\n",
      "application process to apply for a Chase credit card. “Customers” are defined herein as individuals who apply for Chase credit cards through a link\n",
      "in Affiliate’s Web site. Chase shall be responsible for administering application forms and related customer service. All of the rules, operating\n",
      "procedures and policies of Chase regarding customer orders and accounts will apply to orders received through the Links. Chase reserves the right\n",
      "to reject any credit card application in its sole discretion.\n",
      "\n",
      "8. Tracking of Sales\n",
      "\n",
      "Chase will be solely responsible for tracking Approved Accounts made to customers who follow Affiliate’s Links. Affiliate will be solely\n",
      "responsible for ensuring that the Links are formatted properly and maintained in a manner, which allows Chase to track such Approved Accounts.\n",
      "No Commission shall be paid if the Approved Account cannot be tracked by Chase’s system or if the customer accesses the Chase site through\n",
      "means other than the Links. Chase will provide Affiliate with statements of Approved Account activity at the time Commissions are paid.\n",
      "\n",
      "9. Terms and Conditions of Credit Cards\n",
      "\n",
      "Chase is solely responsible for determining the terms and conditions of the credit cards. The credit card offers may vary from time to time and are\n",
      "subject to change. Affiliate may not specify details regarding the Chase credit card on their Websites without the prior approval of Chase.\n",
      "\n",
      "10. Chase Customers\n",
      "\n",
      "Customers who apply for Chase credit cards through the Chase Affiliate Program are customers of Chase. Affiliate has no authority to make or\n",
      "accept any offer on behalf of Chase. All Chase policies regarding customer orders, including availability, pricing and problem resolution, will apply\n",
      "to these customers. Affiliate has no authority to make, and Chase is not responsible for, any representations made by Affiliate that contradict these\n",
      "policies.\n",
      "\n",
      "11. Product Descriptions\n",
      "\n",
      "Affiliate will only use credit card descriptions provided or approved in writing by Chase.\n",
      "\n",
      "12. Copyrighted Material\n",
      "\n",
      "Affiliate is solely responsible for ensuring that its reviews and articles obey all applicable copyright and other laws. Generally, Affiliate must have\n",
      "\n",
      "express permission to use another party’s copyrighted or other proprietary material. Chase is not responsible for Affiliate’s improper use of another\n",
      "party’s copyrighted or proprietary material.\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "13. Commercial Use\n",
      "\n",
      "This program is intended for commercial use only. Commissions are payable for Approved Accounts to third parties who access the Chase URL's\n",
      "(marketing pages) through the Links located on Affiliate’s sponsoring Web site. Affiliates who use this program to apply for credit cards for their\n",
      "own use are NOT in violation of this Agreement.\n",
      "\n",
      "14, Trademarks\n",
      "\n",
      "All Chase trademarks, trade names and service marks (collectively, the “Marks”) are the exclusive property of Chase. Notwithstanding anything set\n",
      "forth in this Agreement, Chase reserves full ownership of the Marks and the Licensed Materials (as defined below). All\n",
      "\n",
      "use of the Marks by Affiliate is limited solely to the use contemplated by this Agreement. All use of Chase Marks by Affiliate is subject to the prior\n",
      "written approval of Chase.\n",
      "\n",
      "15. Licenses and Use of the Chase Logos and Trademarks\n",
      "\n",
      "Chase grants Affiliate a non-exclusive, nontransferable, revocable right to (a) access the Chase site through the links solely in accordance with the\n",
      "terms of this Agreement and (b) solely in connection with such links, to use Chase’s logos, trade names, trademarks, and similar identifying material\n",
      "relating to Chase (collectively, the “Licensed Materials”), for the sole purpose of booking Chase products. Prior to using any of the Licensed\n",
      "Materials, Affiliate will submit to Chase for approval a draft of all proposed material that incorporates the Licensed Materials, together with a brief\n",
      "statement setting forth the proposed use of such materials and any other background or supporting material reasonably requested by Chase to\n",
      "allow Chase to make an informed judgment. All such materials shall be submitted to Chase at least seven (7) days prior to the date of first intended\n",
      "use. Chase will notify Affiliate of its approval or disapproval of such materials within five (5) business days of its receipt of all information required\n",
      "to be submitted.\n",
      "\n",
      "The approval or disapproval of such materials will be in Chase’s sole discretion. Any materials not receiving Chase’s specific written preliminary\n",
      "approval will be deemed disapproved. Affiliate may not alter, modify, or change the Licensed Materials in any way. Affiliate is only entitled to use\n",
      "the licensed materials to the extent that it is a member in good standing of the Chase Affiliate Program. Affiliate agrees not to use the Licensed\n",
      "Materials in any manner that is disparaging or that otherwise portrays Chase in a negative light. Chase may revoke Affiliate’s license at any time.\n",
      "\n",
      "16. Service Interruption\n",
      "\n",
      "Certain technical difficulties may, from time to time, result in service interruptions. Affiliate agrees not to hold Chase responsible for the\n",
      "consequences of such interruptions.\n",
      "\n",
      "17. Indemnification\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "Affiliate hereby agrees to indemnify, defend, and hold harmless Chase, its shareholders, officers, directors, employees, agents, affiliates and their\n",
      "respective directors, officers, employees and agents, successors and assigns, from and against any and all claims, demands, losses, liabilities,\n",
      "damages or expenses (including attorneys’ fees and costs) of any nature whatsoever incurred or suffered by Chase (collectively the “losses”), in so\n",
      "far as such losses (or actions in respect thereof) arise out of, are related to, or are based on (i) the breach of any representation, warranty, or\n",
      "covenant made by Affiliate herein; or (ii) any claim related to Affiliate’s site.\n",
      "\n",
      "18. Confidentiality\n",
      "\n",
      "Except as otherwise provided in this Agreement or with the consent of the other party hereto, each of the parties hereto agrees that all information\n",
      "including, without limitation, the terms of this Agreement, business and financial information, customer and vendor lists, and pricing and sales\n",
      "information, concerning Chase, Customer or Affiliate shall remain strictly confidential and secret and shall not be utilized, directly or indirectly, by\n",
      "such party for its own business purposes or for any other purpose except and solely to the extent necessary to exercise rights and perform\n",
      "obligations under this Agreement. The foregoing restrictions will not apply to information to the extent it (i) was known to the receiving party at the\n",
      "time of disclosure; (ii) has become publicly known through no wrongful act of the receiving party; (iii) has been rightfully received from a third\n",
      "party under no obligation to the disclosing party; (iv) has been disclosed by court order or as otherwise required by law if the receiving party has\n",
      "given the disclosing party a reasonable opportunity to contest or limit the scope of such required disclosure.\n",
      "\n",
      "19. Modification\n",
      "\n",
      "Chase reserves the right to change any and all of the terms and conditions in this Agreement, at any time and in its sole discretion, by posting a\n",
      "new agreement on its Website. Without limiting the generality of the foregoing, the amount of Commissions, the definition of Approved Accounts,\n",
      "and all other provisions of this Agreement are subject to change without notice other than posting such information on the Chase Website. IF ANY\n",
      "MODIFICATION IS UNACCEPTABLE TO AFFILIATE, THE ONLY RECOURSE IS TO TERMINATE THIS AGREEMENT. AFFILIATE’S\n",
      "CONTINUED PARTICIPATION IN THE AFFILIATE PROGRAM FOLLOWING CHASE’S POSTING OF A NEW AGREEMENT ON ITS WEB SITE\n",
      "WILL CONSTITUTE BINDING ACCEPTANCE OF THE CHANGE.\n",
      "\n",
      "20. Warranty Disclaimer\n",
      "\n",
      "Chase makes no warranties, representations or conditions with regard to the Chase Affiliate Program or any services provided hereunder, whether\n",
      "express or implied, arising by law or otherwise, INCLUDING, WITHOUT LIMITATION, ANY IMPLIED WARRANTY OF MERCHANTABILITY OR\n",
      "FITNESS FOR A PARTICULAR PURPOSE OR NONINFRINGEMENT OR ANY IMPLIED WARRANTY ARISING OUT OF COURSE OF\n",
      "PERFORMANCE, COURSE OF DEALING OR USAGE OF TRADE.\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "21. Limitation of Damages\n",
      "\n",
      "Chase shall have no liability for any indirect, incidental, special or consequential damages or any loss of revenue or profits arising under or with\n",
      "respect to this Agreement or the Affiliate Program, regardless of whether Chase has been advised of the possibility of such damages. Further,\n",
      "Chase’s aggregate liability arising under or with respect to this Agreement or the Affiliate Program shall in no event exceed the total Commissions\n",
      "paid or payable by Chase to Affiliate under this\n",
      "\n",
      "Agreement.\n",
      "22. Independent Investigation\n",
      "\n",
      "AFFILIATE ACKNOWLEDGES THAT IT HAS READ THIS AGREEMENT, HAS HAD AN OPPORTUNITY TO CONSULT WITH ITS OWN LEGAL\n",
      "ADVISERS IF IT SO DESIRED, AND AGREES TO ALL ITS TERMS AND CONDITIONS. AFFILIATE AGREES THAT, IN INTERPRETING THIS\n",
      "AGREEMENT, NO WEIGHT SHALL BE PLACED UPON THE FACT THAT THIS AGREEMENT HAS BEEN DRAFTED BY CHASE, AND IT SHALL\n",
      "NOT ASSERT THAT THIS AGREEMENT IS UNENFORCEABLE OR INVALID ON THE GROUNDS THAT IT IS A CONTRACT OF ADHESION,\n",
      "THAT IT IS UNCONSCIONABLE, OR ANY SIMILAR THEORY. AFFILIATE UNDERSTANDS THAT CHASE MAY AT ANY TIME (DIRECTLY OR\n",
      "INDIRECTLY) SOLICIT CUSTOMER REFERRALS ON TERMS THAT MAY DIFFER FROM THOSE CONTAINED IN THIS AGREEMENT.\n",
      "\n",
      "23. Governing Law\n",
      "\n",
      "This Agreement will be governed in all respects by the laws of the State of Delaware, including its conflict with law provisions.\n",
      "Accept.\n",
      "\n",
      "Appendix\n",
      "\n",
      "List of Restricted Trademark Terms\n",
      "\n",
      "Partner Restricted Trademark Terms\n",
      "Chase Brand Add Chase as a negative Keyword to your Search strategy.\n",
      "\n",
      "In addition, the following terms are prohibited: Chase, Chase bank, www.chase.com, www.creditcardsatchase.com, www.chasecreditcard.com,\n",
      "chase.com, creditcardsatchase.com, chasecreditcard.com,\n",
      "chase credit card, chase credit cards, Chase Freedom, Freedom Card\n",
      "\n",
      "AARP AARP.org, AARP.com, AARP membership, AARPmagazine.com, AARPhealthcare.com, AARP foundation, AARP passport,\n",
      "\n",
      "www travelocity.com/AARP, AARP Bulletin, American Association of Retired Persons, AARP Insurance, AARP partner, AARP providers, AARP\n",
      "advocacy, Segunda Juventud, AARP Hot Deals\n",
      "\n",
      "Amazon Amazon, Amazon.com, www.amazon.com, Amazon Books, Amazon DVD, Amazon Movies, Amazon Music\n",
      "\n",
      "Borders Borders, Borders Stores, Borders Books, www.borders.com, www.bordersbooks.com\n",
      "\n",
      "Waldenbooks, Waldenbooks Stores, www.waldenbooks.com, www.waldenbooksstores.com\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "British Air British Airways, British Air, www.britishairways.com, www.ba.com, ba,\n",
      "\n",
      "Continental See Continental Tab\n",
      "\n",
      "Disney See “Disney” Tab\n",
      "\n",
      "Hess Hess, www.hess.com, Amerada\n",
      "\n",
      "Holiday Inn/Priority Club Holiday Inn, Holiday Inn Express, Priority Club, IHG, www. ichotelsgroup.com, InterContinental, InterContinental Hotels\n",
      "Group, Crowne Plaza, Hotel Indigo, Staybridge Suites, Candlewood Suites,\n",
      "\n",
      "Marathon Marathon, Marathon Oil, Marathon Petroleum Company, Speedway, Speedway SuperAmerica, SuperAmerica\n",
      "\n",
      "Marriott www.marriottrewards.com, www.marriott.com, Marriott, Marriott Rewards\n",
      "\n",
      "Overstock overstock.com, www.overstock.com, overstocked.com, overstock/com, overstock com, overstock com, overstockcom, overstock .com,\n",
      "overstock?com, overstock>com, overstock, overstocked.com, overstocks.com,\n",
      "\n",
      "over stock.com, overstock .com, overstockcom\n",
      "\n",
      "Sony Sony, www.sonystyle.com, ImageStation, My Sony, Vaio, EverQuest\n",
      "\n",
      "Speedway Speedway SuperAmerica, Speedway, SuperAmerica, Speedy Rewards, Marathon, Marathon Oil, Marathon Petroleum Company\n",
      "Starbucks Starbucks, Starbucks Coffee, Starbucks Foundation, Starbucks Coffee Company, Starbucks Corporation\n",
      "\n",
      "Subaru Subaru, My Subaru, Subaru World, Subaru of America\n",
      "\n",
      "Toys www.toysrus.com, Toysrus.com, Toys “R” Us, Toys “R” Us International, Kids”R”Us, Babies”R”Us, Babiesrus.com, Toyologist,\n",
      "Toysrus/Amazon, Babiesrus/Amazon, www.personalizedbyrus.com\n",
      "\n",
      "Trump Trump, www.trump.com, The Apprentice, Trumped, Trump University, Trump Taj Mahal, Trump Plaza, Trump Marina, Trump Indiana, Trump\n",
      "Club Privee, Trump National Golf Club, Trump Tower, Trump Park Avenue, Trump World Tower, Trump International Hotel & Tower, Trump Place,\n",
      "Trump Palace, Trump Parc & Trump Parc East, Trump Grande, Mar-a-Lago\n",
      "\n",
      "United See “United” Tab\n",
      "\n",
      "Universal Universal, Universal Studios, Universal Movies, Unviersal Entertainment, Universal Hollywood, www.universal.com, Universal movie\n",
      "tickets, universal movie ticket, universal theme parks, universal discount, universal discounts, universal ticket, universal tickets, universal vacation,\n",
      "universal vacations, universal travel, universal deals, universal offer, universal offers, universal park, universal parks, universal getaway, universal\n",
      "getaways, universal family getaway, universal family getaways, universal deal, universal deals\n",
      "\n",
      "Volkswagen Volkswagen, Volkswagen International, Volkswagen Group, Volkswagen AG, Audi\n",
      "\n",
      "Disney Restricted Key Words\n",
      "\n",
      "cheap disney vacation disney world vacations\n",
      "cheap disney vacations disneyland bargain\n",
      "child vacation disneyland bargains\n",
      "\n",
      "childrens vacations disneyland cheap\n",
      "\n",
      "discount disney travel disneyland discount\n",
      "discount disney vacation disneyland discounts\n",
      "discount disney vacations disneyland offer\n",
      "discount vacation disneyland offers\n",
      "\n",
      "discount vacations disneyland promotion\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "disney disneyland promotions\n",
      "\n",
      "disney bargain disneyland save\n",
      "\n",
      "disney bargains disneyland save\n",
      "\n",
      "disney cheap disneyland savings\n",
      "\n",
      "disney cruise disneyland savings\n",
      "\n",
      "disney cruise vacations disneyland travel\n",
      "disney deal disneyland trip\n",
      "\n",
      "disney discount disneyland trips\n",
      "\n",
      "disney family vacation disneyland vacation\n",
      "disney family vacations disneyland vacations\n",
      "disney florida vacation disneyworld bargain\n",
      "disney florida vacations disneyworld bargains\n",
      "disney golf vacations disneyworld cheap\n",
      "disney honeymoon disneyworld offer\n",
      "\n",
      "disney honeymoon vacation disneyworld offers\n",
      "disney honeymoons disneyworld promotions\n",
      "disney offer disneyworld save\n",
      "\n",
      "disney offers disneyworld savings.\n",
      "\n",
      "disney package disneyworld vacation\n",
      "\n",
      "disney package vacations disneyworld vacations\n",
      "disney promotion family vacation\n",
      "\n",
      "disney promotions family vacations\n",
      "\n",
      "disney resort kid vacation\n",
      "\n",
      "disney resort vacation kids vacations\n",
      "\n",
      "disney resort vacations magic kingdom\n",
      "\n",
      "disney resorts orlando disney vacations\n",
      "\n",
      "disney savings orlando rentals\n",
      "\n",
      "disney travel orlando vacations\n",
      "\n",
      "disney travel package special disney travel\n",
      "disney vacation special vacation packages\n",
      "disney vacation club walt disney bargain\n",
      "disney vacations walt disney bargains\n",
      "\n",
      "disney vacations florida walt disney cheap\n",
      "disney vacations orlando walt disney deal\n",
      "disney world bargain walt disney deals\n",
      "\n",
      "disney world bargains walt disney offer\n",
      "\n",
      "disney world cheap walt disney offers\n",
      "\n",
      "disney world discount walt disney resort vacations\n",
      "disney world offer walt disney save\n",
      "\n",
      "disney world offers walt disney savings\n",
      "\n",
      "disney world package walt disney vacation\n",
      "disney world save walt disney vacations\n",
      "disney world savings walt disney world vacation\n",
      "disney world vacation walt disney world vacations\n",
      "\n",
      "United Restricted Key Words\n",
      "\n",
      "united airlines united air fare\n",
      "\n",
      "united united airlines reservations online\n",
      "united air united airline fare\n",
      "\n",
      "united.com United Escapes\n",
      "\n",
      "united airline international united flights\n",
      "www.united.com untied air\n",
      "\n",
      "united flight united first class\n",
      "unitedairlines.com United Vacation\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "UAL united travel\n",
      "\n",
      "united airlines.com united star alliance\n",
      "\n",
      "ual.com united airlines specials\n",
      "\n",
      "united air lines united discounts\n",
      "www.unitedairlines.com united trip\n",
      "\n",
      "united airlines schedule travel with united\n",
      "\n",
      "united airline travel united airlines discounts\n",
      "united reservation united airlines official website\n",
      "www.ual.com united business class\n",
      "\n",
      "united express united airlines airports\n",
      "\n",
      "united reservations united airlines star alliance\n",
      "www.united airlines.com united non-stop flights\n",
      "united fares united packages\n",
      "\n",
      "united airline flight international united travel\n",
      "united and airlines united airlines economy plus\n",
      "United Vacations united airports\n",
      "\n",
      "united airlines tickets united group travel\n",
      "\n",
      "united airlines flights United Escape\n",
      "\n",
      "united express airlines easy update\n",
      "\n",
      "united flights united air vacations\n",
      "\n",
      "unitedair united fare sale\n",
      "\n",
      "United airfare united last minute fares\n",
      "www.united airlines united efares\n",
      "\n",
      "untied airlines united getaways\n",
      "www.unitedairlines united low fares\n",
      "\n",
      "united airline.com united airlines bookings\n",
      "united air line cities united flies\n",
      "\n",
      "united airlines travel fly on united\n",
      "\n",
      "united airlines homepage united airlines group travel\n",
      "united airlines website united airlines travel certificates\n",
      "united destinations United Easy Update\n",
      "\n",
      "united airline flights united airlines business travel\n",
      "united airlines home page united special deals\n",
      "United airfares united business travel\n",
      "\n",
      "e-fares untiedair\n",
      "\n",
      "united airlines site united economy class\n",
      "\n",
      "united airlines fares united package deals\n",
      "www.unitedairline.com international united ticket\n",
      "united airlines home international united tickets\n",
      "united airlines vacations shop for united flights\n",
      "vacation travel United EasyUpdate\n",
      "\n",
      "united specials fly with united\n",
      "\n",
      "www.united airline.com united e fares\n",
      "\n",
      "unitied airlines united travel certificates\n",
      "\n",
      "united deals united air star alliance\n",
      "\n",
      "international united flight united fare search\n",
      "united airlines online United Escapes\n",
      "\n",
      "united e-fares international united flight\n",
      "\n",
      "united airlines cities united airlines online\n",
      "\n",
      "united air fare united e-fares\n",
      "\n",
      "united airlines reservations online united airlines cities\n",
      "united airline fare\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "Continental Restricted Key Words\n",
      "\n",
      "Continental airlines Continental air fare\n",
      "\n",
      "Continental Continental airlines reservations online\n",
      "continental.com Continental airline fare\n",
      "\n",
      "continental airline international Continental flights\n",
      "www.continental.com Continental air\n",
      "\n",
      "continental flight Continental first class\n",
      "\n",
      "continental air lines Continental Vacation\n",
      "\n",
      "continental airlines schedule Continental travel\n",
      "\n",
      "continental airline travel Continental airlines specials\n",
      "continental reservation Continental discounts\n",
      "\n",
      "continental reservations Continental trip\n",
      "\n",
      "continental fares travel with Continental\n",
      "\n",
      "continental airline flight Continental airlines discounts\n",
      "continental and airlines Continental airlines official website\n",
      "Continental Vacations Continental business class\n",
      "continental airlines tickets Continental airlines airports\n",
      "continental airlines flights Continental non stop flights\n",
      "continental flights\n",
      "\n",
      "continental airlines Continental packages\n",
      "\n",
      "continental air line International Continental travel\n",
      "continental airlines travel Continental airports\n",
      "\n",
      "continental airlines homepage Continental group travel\n",
      "continental airlines website Continental air vacations\n",
      "continental destinations Continental fare sale\n",
      "\n",
      "continental airlines vacations Continental last minute fares\n",
      "continental air fare Continental getaways\n",
      "\n",
      "continental airlines reservations online Continental low fares\n",
      "continental airline fare Continental airlines bookings\n",
      "international continental flight cities Continental flies\n",
      "continental airlines online fly on Continental\n",
      "\n",
      "continental airlines cities Continental airlines group travel\n",
      "Continental economy class Continental airlines travel certificates\n",
      "Continental package deals Continental airlines business travel\n",
      "international Continental ticket Continental special deals\n",
      "international Continental tickets Continental business travel\n",
      "shop for Continental flights fly with Continental\n",
      "\n",
      "Source: CREDITCARDS.COM, INC., S-1, 8/10/2007\n",
      "\n",
      "\n",
      "\n",
      "Simplified Text:\n",
      " : Exhibit 10.33 Last Update: April 6, 2007 CHASE AFFILIATE AGREEMENT THIS AGREEMENT sets forth the terms and conditions agreed to by Chase Bank USA, N.A. (?Chase?) and you as an “Affiliate” in the Chase Affiliate Program (the “Affiliate Program”). AFFILIATE CERTIFIES THAT YOU HAVE READ AND UNDERSTAND THE TERMS SET FORTH BELOW, AND THAT YOU AREAU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 1️⃣ Imports\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 2️⃣ Load the T5 model (pretrained)\n",
    "model_name = \"t5-small\"  # lightweight T5 for simplification\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 3️⃣ Function to simplify text\n",
    "def simplify_text(text):\n",
    "    input_text = \"simplify: \" + text  # T5 task prefix\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_length=150, \n",
    "        num_beams=4, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    simplified = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return simplified\n",
    "\n",
    "# 4️⃣ Example usage\n",
    "# ocr_text = \"\"\"\n",
    "# To enroll in the Affiliate Program, you must submit a complete “Affiliate Registration Form” via the Chase Affiliate Website. \n",
    "# Chase will evaluate your registration form and may reject your site if it contains restricted content such as offensive, illegal, or sexually explicit material.\n",
    "# \"\"\"\n",
    "\n",
    "simplified_version = simplify_text(ocr_text)\n",
    "print(\"Original Text:\\n\", ocr_text)\n",
    "print(\"\\nSimplified Text:\\n\", simplified_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e810610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b5e9bd",
   "metadata": {},
   "source": [
    "\n",
    "# Contract Simplification & Risk Prediction (Constitution of India)\n",
    "**What this notebook adds:**\n",
    "\n",
    "- Load and flatten a JSON file containing the Constitution (articles & clauses)\n",
    "\n",
    "- Preprocess text and create datasets for two tasks:\n",
    "  1. **Summarization (seq2seq)** — fine-tune a Hugging Face summarization model.\n",
    "  2. **Risk classification** — train a classifier to predict a risk level from article text.\n",
    "\n",
    "**Notes:**\n",
    "- This notebook **prepares** the pipeline and includes fully commented functions. It does **not** require you to run long trainings here immediately; run in an environment with GPU (Colab / local with CUDA) for training.\n",
    "- If your JSON already contains summary targets and risk labels, the notebook will use them. If not, it shows options to generate pseudo-summaries or heuristic risk labels (but manual labeling is recommended for best accuracy).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fba46d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Install required packages\n",
    "Run this cell first in a fresh environment (Colab/local). If you already have `transformers`, `datasets`, and `evaluate`, you can skip installation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18913c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q transformers datasets evaluate sentencepiece accelerate scikit-learn nltk\n",
    "# (Uncomment and run the above line in your runtime to install required packages)\n",
    "print('Installation cell — uncomment the pip line if packages are missing in your environment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11755f",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load and flatten the JSON file\n",
    "This function loads a JSON containing a nested structure of Articles and Clauses and flattens it to a table with columns: `id`, `ArtNo`, `Name`, `text`. It is robust to a few JSON layout variations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63407610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, pandas as pd, os, re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def load_constitution(json_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and flatten a Constitution JSON into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        json_path: path to the JSON file (expected to be a list/dict structure similar to the example).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns ['id', 'ArtNo', 'Name', 'text'] where each clause/article is one row.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f'JSON file not found: {json_path}')\n",
    "\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    def recurse(items):\n",
    "        # items may be list or dict\n",
    "        if isinstance(items, dict):\n",
    "            # If dict looks like an article\n",
    "            art_no = items.get('ArtNo', '')\n",
    "            name = items.get('Name', '')\n",
    "            art_desc = items.get('ArtDesc') or items.get('Description') or ''\n",
    "            if art_desc:\n",
    "                rows.append({'ArtNo': str(art_no), 'Name': name, 'text': art_desc})\n",
    "            clauses = items.get('Clauses') or items.get('clauses') or []\n",
    "            for c in clauses:\n",
    "                if isinstance(c, dict):\n",
    "                    clause_no = c.get('ClauseNo', '')\n",
    "                    clause_desc = c.get('ClauseDesc') or c.get('text') or c.get('clauseDesc') or ''\n",
    "                    if clause_desc:\n",
    "                        rows.append({'ArtNo': f\"{art_no}.{clause_no}\", 'Name': name, 'text': clause_desc})\n",
    "        elif isinstance(items, list):\n",
    "            for it in items:\n",
    "                recurse(it)\n",
    "\n",
    "    recurse(data)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise ValueError('No articles/clauses were found after parsing the JSON — check the JSON structure.')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['id'] = df.index.astype(str)\n",
    "    # reorder\n",
    "    df = df[['id', 'ArtNo', 'Name', 'text']]\n",
    "    return df\n",
    "\n",
    "# Example usage (update path to your JSON file):\n",
    "# df = load_constitution('/path/to/constitution.json')\n",
    "# df.head()\n",
    "print('Loaded load_constitution function — call it with your JSON file path to get a DataFrame.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02acab1",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Preprocessing helpers\n",
    "Functions to clean text and chunk very long articles (recommended for long seq2seq inputs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')  # Uncomment and run once in your environment if punkt is not available\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Basic cleaning: normalize whitespace and preserve sentence boundaries.\n",
    "\n",
    "    Args:\n",
    "        text: raw article/clause text\n",
    "    Returns:\n",
    "        cleaned text\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # normalize newlines and whitespace\n",
    "    t = text.replace('\\r', '\\n')\n",
    "    # collapse repeated newlines\n",
    "    t = re.sub(r\"\\n{2,}\", '\\n', t)\n",
    "    # remove leading/trailing whitespace\n",
    "    t = t.strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_sentences: int = 8) -> List[str]:\n",
    "    \"\"\"Split a long article into smaller chunks by sentences.\n",
    "\n",
    "    Args:\n",
    "        text: cleaned text\n",
    "        max_sentences: maximum sentences per chunk\n",
    "    Returns:\n",
    "        list of text chunks\n",
    "    \"\"\"\n",
    "    sents = sent_tokenize(text)\n",
    "    if len(sents) <= max_sentences:\n",
    "        return [text]\n",
    "    chunks = []\n",
    "    for i in range(0, len(sents), max_sentences):\n",
    "        chunks.append(' '.join(sents[i:i+max_sentences]))\n",
    "    return chunks\n",
    "\n",
    "print('Preprocessing helpers ready (clean_text, chunk_text).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ac8ef",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Preparing summarization targets\n",
    "**Important:** Supervised fine-tuning of a summarization model requires *target summaries* for each input. If your JSON already contains gold summaries, the notebook will use them (look for a field named `summary` or similar).\n",
    "\n",
    "If you don't have gold summaries you have options:\n",
    "- **Manual annotation** (best quality) — create short summaries for a subset of articles.\n",
    "- **Pseudo-labeling** — use an existing pretrained summarization model to create initial summaries, then fine-tune on those (a form of self-training). This is quicker but may reinforce existing model biases.\n",
    "\n",
    "Below we add a helper that will generate pseudo summaries if you have `transformers` available in the runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf26ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pseudo_summaries(df: pd.DataFrame, model_name: str = 'facebook/bart-large-cnn', batch_size: int = 4):\n",
    "    \"\"\"Generate pseudo-summaries using a pretrained summarization model.\n",
    "\n",
    "    NOTE: this will download a model from Hugging Face and requires internet + transformers installed.\n",
    "    Use this only if you understand the caveats (pseudo-labels are noisy).\n",
    "\n",
    "    Returns a new DataFrame with a 'summary' column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from transformers import pipeline\n",
    "    except Exception as e:\n",
    "        raise RuntimeError('transformers package required to generate pseudo summaries. Install it and try again.')\n",
    "\n",
    "    summarizer = pipeline('summarization', model=model_name)\n",
    "    summaries = []\n",
    "    for i, row in df.iterrows():\n",
    "        text = clean_text(row['text'])\n",
    "        # truncation/safe approach: only send first N characters (adjust for your runtime)\n",
    "        text_for_model = text[:4000]\n",
    "        out = summarizer(text_for_model, truncation=True)\n",
    "        summaries.append(out[0]['summary_text'])\n",
    "    new_df = df.copy()\n",
    "    new_df['summary'] = summaries\n",
    "    return new_df\n",
    "\n",
    "print('Pseudo-summary helper added (requires transformers pipeline).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d7c1b",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Risk labeling (heuristic + using provided labels)\n",
    "If your JSON already includes a `risk` field per article/clause, the notebook will use it. Otherwise a simple heuristic function is provided to create labels (LOW/MEDIUM/HIGH) based on keywords. **Manual labeling is strongly recommended** for production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e475160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def label_risk_heuristic(text: str) -> int:\n",
    "    \"\"\"Heuristic risk labeller. Returns 0 (LOW), 1 (MEDIUM), 2 (HIGH).\n",
    "\n",
    "    This is a heuristic function that looks for keywords often associated with 'risk' (e.g., 'penalty', 'prohibited', 'suspend', 'emergency', 'fine', 'offence').\n",
    "    It's only a starting point — replace with human labels when possible.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    high = ['emergency', 'suspend', 'penalty', 'offence', 'offence', 'offender', 'criminal', 'liable', 'fined', 'imprison', 'detention']\n",
    "    medium = ['restriction', 'shall not', 'liable', 'responsible', 'obligation', 'duty', 'penalties']\n",
    "    score = 0\n",
    "    for k in high:\n",
    "        if k in t:\n",
    "            score += 2\n",
    "    for k in medium:\n",
    "        if k in t:\n",
    "            score += 1\n",
    "    if score >= 3:\n",
    "        return 2\n",
    "    elif score >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print('Heuristic label_risk_heuristic function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78725b20",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Build `datasets.Dataset` objects for training\n",
    "This cell shows how to create HF `datasets` objects from the DataFrame and tokenize them. For summarization we create `input_text` and `summary` columns. For classification we create `text` and `label` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d331a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def prepare_datasets_for_training(df: pd.DataFrame, tokenizer_name: str = 't5-small', max_input_length: int = 512, max_target_length: int = 128):\n",
    "    \"\"\"Prepare HF `datasets` for summarization & classification.\n",
    "\n",
    "    - Expects df to have columns: 'id', 'text', optionally 'summary', optionally 'risk' or 'label'\n",
    "    - Returns a dict with 'summarization' and 'classification' Dataset objects (train/valid split applied).\n",
    "    \"\"\"\n",
    "    # Clean text column\n",
    "    df2 = df.copy()\n",
    "    df2['text'] = df2['text'].apply(clean_text)\n",
    "\n",
    "    # Build a summarization dataset if 'summary' exists, otherwise empty\n",
    "    summ_df = None\n",
    "    if 'summary' in df2.columns:\n",
    "        summ_df = df2[['id','text','summary']].rename(columns={'text':'input_text','summary':'target_summary'})\n",
    "        summ_ds = Dataset.from_pandas(summ_df)\n",
    "    else:\n",
    "        summ_ds = None\n",
    "\n",
    "    # Build classification dataset\n",
    "    if 'risk' in df2.columns:\n",
    "        df2['label'] = df2['risk'].astype(int)\n",
    "    else:\n",
    "        df2['label'] = df2['text'].apply(label_risk_heuristic)\n",
    "\n",
    "    cls_df = df2[['id','text','label']]\n",
    "    cls_ds = Dataset.from_pandas(cls_df)\n",
    "\n",
    "    # Simple train/validation split\n",
    "    cls_train_test = cls_ds.train_test_split(test_size=0.1, seed=42)\n",
    "    datasets_dict = {'classification': cls_train_test}\n",
    "    if summ_ds is not None:\n",
    "        summ_train_test = summ_ds.train_test_split(test_size=0.1, seed=42)\n",
    "        datasets_dict['summarization'] = summ_train_test\n",
    "\n",
    "    return datasets_dict\n",
    "\n",
    "print('prepare_datasets_for_training helper created (requires datasets package to run).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6754754",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (Optional) Fine-tune a summarization model (example: T5/BART)\n",
    "This cell provides a **complete** Seq2Seq training boilerplate using the Hugging Face `Seq2SeqTrainer`. **Do not** run this unless you have GPU + sufficient RAM and `transformers`, `datasets`, and `accelerate` installed.\n",
    "\n",
    "Key functions are fully documented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: this cell is an example/training recipe. Run only in a proper runtime (GPU recommended).\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "def make_tokenizer_and_model(model_name: str = 't5-small'):\n",
    "    \"\"\"Load tokenizer and seq2seq model. Change model_name to a larger model if you have resources.\n",
    "\n",
    "    Returns (tokenizer, model)\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "# Example of how to preprocess for seq2seq\n",
    "\n",
    "def preprocess_for_summarization(examples, tokenizer, max_input_length=512, max_target_length=128):\n",
    "    \"\"\"Tokenize inputs ('input_text') and targets ('target_summary') for seq2seq.\n",
    "    Returns tokenized dict for Trainer.\n",
    "    \"\"\"\n",
    "    inputs = [clean_text(x) for x in examples['input_text']]\n",
    "    targets = [x for x in examples['target_summary']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# compute_metrics example using ROUGE\n",
    "\n",
    "def compute_rouge_metrics(preds, labels, tokenizer):\n",
    "    rougelib = evaluate.load('rouge')\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rougelib.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return result\n",
    "\n",
    "\n",
    "# TRAINING: Example (do not run here unless ready)\n",
    "# tokenizer, model = make_tokenizer_and_model('t5-small')\n",
    "# datasets = prepare_datasets_for_training(df_with_summaries, tokenizer_name='t5-small')\n",
    "# train_dataset = datasets['summarization']['train']\n",
    "# val_dataset = datasets['summarization']['test']\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir='./summarization-checkpoint',\n",
    "#     per_device_train_batch_size=4,\n",
    "#     per_device_eval_batch_size=4,\n",
    "#     predict_with_generate=True,\n",
    "#     logging_steps=50,\n",
    "#     evaluation_strategy='steps',\n",
    "#     eval_steps=200,\n",
    "#     save_steps=500,\n",
    "#     num_train_epochs=3,\n",
    "#     fp16=False\n",
    "# )\n",
    "# trainer = Seq2SeqTrainer(model=model, args=training_args, tokenizer=tokenizer, data_collator=data_collator,\n",
    "#                         train_dataset=train_dataset, eval_dataset=val_dataset)\n",
    "# trainer.train()\n",
    "\n",
    "print('Summarization training boilerplate ready (read comments before running).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de709a",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Fine-tune a classifier (example: DistilBERT) for risk prediction\n",
    "This uses `AutoModelForSequenceClassification` + Trainer. Make sure `datasets`, `transformers` and `evaluate` are installed and run on GPU if possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f569b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_risk_classifier(train_dataset, eval_dataset, model_name='distilbert-base-uncased', num_labels=3, output_dir='./risk-classifier'):\n",
    "    \"\"\"Fine-tune a transformer-based classifier using Hugging Face Trainer.\n",
    "\n",
    "    Args:\n",
    "        train_dataset, eval_dataset: HF datasets (already tokenized)\n",
    "        model_name: pretrained transformer\n",
    "        num_labels: number of target classes (e.g., 3 for LOW/MED/HIGH)\n",
    "        output_dir: where to save the trained model\n",
    "\n",
    "    Returns:\n",
    "        trainer object (call trainer.train() to run training)\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # A small helper to tokenize the datasets\n",
    "    def tokenize_fn(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenize_fn, batched=True)\n",
    "    tokenized_eval = eval_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=200,\n",
    "        logging_steps=50,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        save_steps=500,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "print('Classifier training helper defined (Trainer-based).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bafa69",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Inference helpers\n",
    "These functions show how to run the summarization and classification models once they are trained or loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd96f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_text(text: str, tokenizer, model, device='cpu', max_input_length=1024, max_target_length=150):\n",
    "    \"\"\"Generate a summary for `text` using a seq2seq model + tokenizer.\n",
    "\n",
    "    Returns the generated summary string.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, truncation=True, max_length=max_input_length, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    # generate\n",
    "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=max_target_length, num_beams=4)\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def predict_risk(text: str, tokenizer, model, device='cpu') -> int:\n",
    "    \"\"\"Predict risk label (int) for given text using a sequence classifier.\n",
    "\n",
    "    Returns an integer label (0/1/2). You can map these to strings externally.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    inputs = tokenizer(text, truncation=True, max_length=256, return_tensors='pt')\n",
    "    inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    pred = int(torch.argmax(probs, dim=-1).cpu().numpy()[0])\n",
    "    return pred\n",
    "\n",
    "print('Inference helper functions added.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814575a5",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Example workflow (what to run, in order)\n",
    "1. Install dependencies (pip) and ensure GPU is available for training.\n",
    "2. Place your constitution JSON somewhere accessible (e.g., `/content/constitution.json` in Colab).\n",
    "3. Run the **Load** cell: `df = load_constitution('/path/to/constitution.json')`.\n",
    "4. (Optional) Create pseudo summaries: `df_with_summ = generate_pseudo_summaries(df)` — only if you don't have gold summaries.\n",
    "5. Prepare datasets: `datasets = prepare_datasets_for_training(df_with_summ_or_df)`.\n",
    "6. For summarization: follow the Seq2SeqTrainer boilerplate to train.\n",
    "7. For risk classifier: use `train_risk_classifier()` helper to get a Trainer and run `trainer.train()`.\n",
    "8. Run inference using `summarize_text()` and `predict_risk()`.\n",
    "\n",
    "Below is a small code snippet showing these steps programmatically (edit paths and model names as you need).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (do not run verbatim unless paths/models exist in your environment):\n",
    "# json_path = '/path/to/constitution.json'\n",
    "# df = load_constitution(json_path)\n",
    "# # If you have no summaries, create pseudo: df = generate_pseudo_summaries(df)\n",
    "# datasets = prepare_datasets_for_training(df, tokenizer_name='t5-small')\n",
    "# # For classification\n",
    "# cls_train = datasets['classification']['train']\n",
    "# cls_eval = datasets['classification']['test']\n",
    "# trainer = train_risk_classifier(cls_train, cls_eval, model_name='distilbert-base-uncased')\n",
    "# trainer.train()\n",
    "# # For summarization: follow the Seq2Seq cell to construct a trainer and train\n",
    "print('Example workflow cell: edit the paths and run in your environment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b307a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Final notes & recommendations\n",
    "- **Manual labeling:** For risk prediction, create a labeled dataset (even 200-500 human-labeled examples) — heuristics are a start but human labels give far better results.\n",
    "- **Summaries:** Gold summaries are best. If you must pseudo-label, clean and spot-check generated summaries.\n",
    "- **Evaluation:** Use `rouge` for summarization and `accuracy`, `f1` for classification. Validate on holdout sets.\n",
    "- **Deployment:** For inference-only use, you can host the summarization and classifier models (Hugging Face Hub or your own endpoints) and call them via REST.\n",
    "\n",
    "If you want, I can now:\n",
    "- Put together a smaller runnable demo (that uses a tiny model and trains for 1 epoch on a subset) inside this notebook so you can run it even on CPU for testing.\n",
    "- Or modify the heuristic rules / labeling to match your exact risk definitions.\n",
    "\n",
    "Tell me which of the two you'd like next, and I will add the demo cell right into the notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
